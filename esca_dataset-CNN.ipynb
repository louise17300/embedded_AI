{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"esca_dataset-CNN.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMkX9UCnZv/2FgnP9IRdkpZ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mfwQTFZl9Gf7"},"source":["# **Preprocessing Dataset**"]},{"cell_type":"markdown","metadata":{"id":"TMcgVaRpXC0g"},"source":["**UNZIP DATASET**"]},{"cell_type":"code","metadata":{"id":"f2FZ7OoQAOcb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tv1MNz0EA8uT"},"source":["dataset_name = \"/content/drive/MyDrive/augmented_esca_dataset\"\r\n","dataset_destination = \"/content/drive/MyDrive/augmented_esca_dataset\"\r\n","\r\n","!unzip  $dataset_name\".zip\" -d $dataset_destination\r\n","!ls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ss4aXqoi9OaZ"},"source":["**LIBRARIES**"]},{"cell_type":"code","metadata":{"id":"MKV_DpMO9dI5"},"source":["from PIL import Image\r\n","import numpy as np\r\n","from numpy import random\r\n","\r\n","\r\n","import os\r\n","import pathlib\r\n","import random"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r5L_AeAq9JhF"},"source":["**DIRECTORY**"]},{"cell_type":"code","metadata":{"id":"lnNOs8QB9eek"},"source":["# directory of dataset\r\n","dir_original = \"/content/drive/MyDrive/augmented_esca_dataset/content/esca_dataset/augmented_esca_dataset\"\r\n","\r\n","# name of new dataset\r\n","dir_processed = \"/content/drive/MyDrive/augmented_esca_dataset_splited\"\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xL2JPD_S9QJr"},"source":["**PARAMETERS**"]},{"cell_type":"code","metadata":{"id":"cxtO-Z769gZe"},"source":["# size of new images\r\n","size = 1280, 720"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uPd-i4dw9TbW"},"source":["**EXTRACTION OF DATASET INFORMATION**"]},{"cell_type":"code","metadata":{"id":"yWYUjeDB9iEz"},"source":["data_dir = pathlib.Path(dir_original)\r\n","\r\n","set_samples = ['train', 'validation', 'test']\r\n","print(\"set_samples: \", set_samples, \"\\n\")\r\n","\r\n","CLASS_NAMES = np.array([item.name for item in sorted(data_dir.glob('*'))])\t\t\t\t\t\t\t\t\t\t\t\t\r\n","print(\"class: \", CLASS_NAMES, \"\\n\")\r\n","\r\n","N_IMAGES = np.array([len(list(data_dir.glob(item.name+'/*.jpg'))) for item in sorted(data_dir.glob('*'))])\t\t\t# number of images for class\r\n","print(\"number of images for class: \", N_IMAGES, \"\\n\")\r\n","\r\n","N_samples = np.array([(int(np.around(n*60/100)), int(np.around(n*15/100)), int(np.around(n*25/100))) for n in N_IMAGES])\t# number of images for set (train,validation,test)\r\n","print(\"split of dataset: \\n \", N_samples, \"\\n\")\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmhOzI_Y9W8B"},"source":["**PREPROCESSING DATASET**"]},{"cell_type":"code","metadata":{"id":"Fsf53Pzk7xgT"},"source":["# Create the new dataset\r\n","# Split Dataset\t\t\t\t\t\t\t\t(also resize and rotate)\r\n","\r\n","\r\n","\r\n","# create the dataset folder\t\t\t***********************************\r\n","os.makedirs(dir_processed)\r\n","\r\n","for set_tag in set_samples:\r\n","\tos.makedirs(dir_processed + '/' + set_tag)\r\n","\r\n","\tfor class_name in CLASS_NAMES:\r\n","\t\tos.makedirs(dir_processed + '/' + set_tag + '/' + class_name)\r\n","\r\n","\r\n","\r\n","# SPLIT DATASET (and resize)\t\t*************************************\r\n","print(\"Split dataset.....\")\r\n","\r\n","i=0\r\n","j=0\r\n","k=0\r\n","for class_name in CLASS_NAMES:\t\t\t\t\t\t\t\t\t\t\t\t\t\t# \"j\" cambia con il tipo di pianta [0,3]\r\n","\t\r\n","    print(\"class name: \", class_name)\r\n","\r\n","    contatore_samples = 0\r\n","    k=0\r\n","\r\n","    array = sorted(os.listdir(dir_original + '/' + class_name))\r\n","    #random.shuffle(array)\r\n","\r\n","    for image_name in array:\t                                       \t# \"contatore\" si azzera ad ogni campo 'train' 'validation' 'test'\r\n","\t\r\n","        print(\"image: \", i)\r\n","        i=i+1\r\n","\r\n","        if contatore_samples==N_samples[j][k]:\t\t\t\t\t\t\t\t\t\t    # \"k\" cambia con train, validation, e test\r\n","            k+=1\r\n","            contatore_samples=0\r\n","\r\n","\r\n","        img=Image.open(dir_original +'/'+class_name+'/'+image_name)\r\n","        l,_ = img.size\r\n","        l=int(l)\r\n","        \r\n","        \r\n","        if l==1080 or l==720:\r\n","        \r\n","            transposed = img.transpose(Image.ROTATE_90)\r\n","            transposed.thumbnail(size)\r\n","            transposed.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\r\n","        \r\n","        else:\r\n","        \r\n","            img.thumbnail(size)\r\n","            img.save(dir_processed+'/'+set_samples[k]+'/'+class_name+'/'+image_name)\r\n","\r\n","        contatore_samples+=1\t\r\n","\r\n","    j+=1\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5ecfMI2lffI"},"source":["# **MODEL for ESCA DATASET**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"BhxyVMvTlipG"},"source":["LIBRARY"]},{"cell_type":"code","metadata":{"id":"_X5lBUEJmN0k"},"source":["import tensorflow as tf\n"," \n","from tensorflow import keras\n"," \n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n"," \n","from tensorflow.keras.preprocessing import image_dataset_from_directory\n"," \n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ituslInJllsc"},"source":["DIRECTORY"]},{"cell_type":"code","metadata":{"id":"eFNFmre4mOig"},"source":["# cartelle contenenti il dataset\n"," \n","PATH_DATASET = '/content/drive/MyDrive/augmented_esca_dataset_splited'\n"," \n","train_data_dir = os.path.join(PATH_DATASET, 'train')\n","validation_data_dir = os.path.join(PATH_DATASET, 'validation')\n","test_data_dir = os.path.join(PATH_DATASET, 'test')\n"," \n"," \n"," \n","# nomi dei file da creare\n"," \n","PATH_MODELS = '/content/drive/MyDrive/Colab Notebooks/PAPER_1'\n"," \n","name_model_small = os.path.join(PATH_MODELS, 'model_small_b32.h5')\n","name_model_medium = os.path.join(PATH_MODELS, 'model_medium_b32.h5')\n","name_model_large = os.path.join(PATH_MODELS, 'model_large_b32.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i0RNUATslnli"},"source":["PARAMETERS"]},{"cell_type":"code","metadata":{"id":"_BhD4g_MmPMr"},"source":["batch_size = 32\n"," \n","nb_train_samples = 14868\n","nb_validation_samples = 3717\n","nb_test_samples = 6195\n"," \n","n_class = 2\n"," \n","epochs = 50"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WQ9_a0bYAwq"},"source":["# **MODEL LARGE**"]},{"cell_type":"code","metadata":{"id":"7Rlacu5qYBhn"},"source":["start = time.time()\r\n","\r\n","# image size (Model Medium)\r\n","img_width, img_height = 1280, 720\r\n","\r\n","# input shape\r\n","if keras.backend.image_data_format() == 'channels_first':\r\n","    input_shape = (3, img_width, img_height)\r\n","else:\r\n","    input_shape = (img_width, img_height, 3)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ************        DATASET       *************************************\r\n","# ***********************************************************************\r\n","\r\n","train_dataset = image_dataset_from_directory(train_data_dir,\r\n","                                             shuffle=True,\r\n","                                             batch_size=batch_size,\r\n","                                             image_size=(img_width, img_height),\r\n","                                             label_mode='categorical')\r\n","\r\n","\r\n","validation_dataset = image_dataset_from_directory(validation_data_dir,\r\n","                                                  shuffle=True,\r\n","                                                  batch_size=batch_size,\r\n","                                                  image_size=(img_width, img_height),\r\n","                                                  label_mode='categorical')\r\n","\r\n","\r\n","test_dataset = image_dataset_from_directory(test_data_dir,\r\n","                                            shuffle=True,\r\n","                                            batch_size=batch_size,\r\n","                                            image_size=(img_width, img_height),\r\n","                                            label_mode='categorical')\r\n","\r\n","\r\n","# preprocessing: input scaling (./255)\r\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\r\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\r\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\r\n","\r\n","\r\n","# Configure the dataset for performance\r\n","\r\n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n","\r\n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# **************        MODEL       *************************************\r\n","# ***********************************************************************\r\n","\r\n","model_large = Sequential()\r\n","model_large.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_large.add(Conv2D(64, (3, 3), padding='same'))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_large.add(Conv2D(32, (3, 3), padding='same'))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_large.add(Flatten())\r\n","model_large.add(Dense(64))\r\n","model_large.add(Activation('relu'))\r\n","model_large.add(Dropout(0.5))\r\n","model_large.add(Dense(2))\t\t\t#because we have 2 class\r\n","model_large.add(Activation('softmax'))\r\n","\r\n","model_large.summary()\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *******************        COMPILATION       **************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","model_large.compile(loss='categorical_crossentropy',\r\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\r\n","            metrics=['accuracy'])\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *******************        TRAINING       *****************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","with tf.device('/device:GPU:0'):\r\n","\r\n","  history = model_large.fit(\r\n","    train_dataset,\r\n","    epochs=epochs,\r\n","    validation_data=validation_dataset)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *****************        SAVE MODEL        ****************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","model_large.save(name_model_large)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ********************        PLOT RESULTS        ***********************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss = history.history['loss']\r\n","val_loss = history.history['val_loss']\r\n","\r\n","epochs_range = range(epochs)\r\n","\r\n","plt.figure(figsize=(8, 8))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(epochs_range, acc, label='Training Accuracy')\r\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(epochs_range, loss, label='Training Loss')\r\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\r\n","plt.show()\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ***********************        TEST        ****************************\r\n","# ***********************************************************************\r\n","\r\n","with tf.device('/device:GPU:0'):\r\n","\r\n","  test_result = model_large.evaluate(test_dataset)\r\n","\r\n","  \r\n","print(\"size of images: \", img_width,img_height)\r\n","print(\"test_result: \", test_result)\r\n","\r\n","\r\n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UsAyqNAKaFjJ"},"source":["# **MODEL SMALL**"]},{"cell_type":"code","metadata":{"id":"QSAhC_EFaHdD"},"source":["start = time.time()\n"," \n","# image size (Model Small)\n","img_width, img_height = 80, 45\n"," \n","# input shape\n","if keras.backend.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ************        DATASET       *************************************\n","# ***********************************************************************\n"," \n","train_dataset = image_dataset_from_directory(train_data_dir,\n","                                             shuffle=True,\n","                                             batch_size=batch_size,\n","                                             image_size=(img_width, img_height),\n","                                             label_mode='categorical')\n"," \n"," \n","validation_dataset = image_dataset_from_directory(validation_data_dir,\n","                                                  shuffle=True,\n","                                                  batch_size=batch_size,\n","                                                  image_size=(img_width, img_height),\n","                                                  label_mode='categorical')\n"," \n"," \n","test_dataset = image_dataset_from_directory(test_data_dir,\n","                                            shuffle=True,\n","                                            batch_size=batch_size,\n","                                            image_size=(img_width, img_height),\n","                                            label_mode='categorical')\n"," \n"," \n","# preprocessing: input scaling (./255)\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\n"," \n"," \n","# Configure the dataset for performance\n"," \n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\n"," \n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n"," \n"," \n"," \n"," \n","# ***********************************************************************\n","# **************        MODEL       *************************************\n","# ***********************************************************************\n"," \n","model_small = Sequential()\n","model_small.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(64, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Conv2D(32, (3, 3), padding='same'))\n","model_small.add(Activation('relu'))\n","model_small.add(MaxPooling2D(pool_size=(2, 2)))\n"," \n","model_small.add(Flatten())\n","model_small.add(Dense(64))\n","model_small.add(Activation('relu'))\n","model_small.add(Dropout(0.5))\n","model_small.add(Dense(2))           #because we have 2 class\n","model_small.add(Activation('softmax'))\n"," \n","model_small.summary()\n"," \n"," \n","# ***********************************************************************\n","# *******************        COMPILATION       **************************\n","# ***********************************************************************\n"," \n"," \n","model_small.compile(loss='categorical_crossentropy',\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\n","            metrics=['accuracy'])\n"," \n"," \n"," \n","# ***********************************************************************\n","# *******************        TRAINING       *****************************\n","# ***********************************************************************\n"," \n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  history = model_small.fit(\n","    train_dataset,\n","    epochs=epochs,\n","    validation_data=validation_dataset)\n"," \n"," \n"," \n","# ***********************************************************************\n","# *****************        SAVE MODEL        ****************************\n","# ***********************************************************************\n"," \n"," \n","model_small.save(name_model_small)\n"," \n"," \n"," \n","# ***********************************************************************\n","# ********************        PLOT RESULTS        ***********************\n","# ***********************************************************************\n"," \n"," \n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n"," \n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n"," \n","epochs_range = range(epochs)\n"," \n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training Accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\n"," \n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\n","plt.show()\n"," \n"," \n"," \n","# ***********************************************************************\n","# ***********************        TEST        ****************************\n","# ***********************************************************************\n"," \n","with tf.device('/device:GPU:0'):\n"," \n","  test_result = model_small.evaluate(test_dataset)\n"," \n","  \n","print(\"size of images: \", img_width,img_height)\n","print(\"test_result: \", test_result)\n"," \n"," \n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qK6gqFKXWtUv"},"source":["# **MODEL MEDIUM**"]},{"cell_type":"code","metadata":{"id":"4xArrgnbWt3y"},"source":["start = time.time()\r\n","\r\n","# image size (Model Medium)\r\n","img_width, img_height = 320, 180\r\n","\r\n","# input shape\r\n","if keras.backend.image_data_format() == 'channels_first':\r\n","    input_shape = (3, img_width, img_height)\r\n","else:\r\n","    input_shape = (img_width, img_height, 3)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ************        DATASET       *************************************\r\n","# ***********************************************************************\r\n","\r\n","train_dataset = image_dataset_from_directory(train_data_dir,\r\n","                                             shuffle=True,\r\n","                                             batch_size=batch_size,\r\n","                                             image_size=(img_width, img_height),\r\n","                                             label_mode='categorical')\r\n","\r\n","\r\n","validation_dataset = image_dataset_from_directory(validation_data_dir,\r\n","                                                  shuffle=True,\r\n","                                                  batch_size=batch_size,\r\n","                                                  image_size=(img_width, img_height),\r\n","                                                  label_mode='categorical')\r\n","\r\n","\r\n","test_dataset = image_dataset_from_directory(test_data_dir,\r\n","                                            shuffle=True,\r\n","                                            batch_size=batch_size,\r\n","                                            image_size=(img_width, img_height),\r\n","                                            label_mode='categorical')\r\n","\r\n","\r\n","# preprocessing: input scaling (./255)\r\n","train_dataset = train_dataset.map(lambda images, labels: (images/255, labels))\r\n","validation_dataset = validation_dataset.map(lambda images, labels: (images/255, labels))\r\n","test_dataset = test_dataset.map(lambda images, labels: (images/255, labels))\r\n","\r\n","\r\n","# Configure the dataset for performance\r\n","\r\n","#AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n","\r\n","#train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","#validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","#test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\r\n","\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# **************        MODEL       *************************************\r\n","# ***********************************************************************\r\n","\r\n","model_medium = Sequential()\r\n","model_medium.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_medium.add(Conv2D(32, (3, 3), padding='same'))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_medium.add(Conv2D(64, (3, 3), padding='same'))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_medium.add(Conv2D(64, (3, 3), padding='same'))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_medium.add(Conv2D(32, (3, 3), padding='same'))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(MaxPooling2D(pool_size=(2, 2)))\r\n","\r\n","model_medium.add(Flatten())\r\n","model_medium.add(Dense(64))\r\n","model_medium.add(Activation('relu'))\r\n","model_medium.add(Dropout(0.5))\r\n","model_medium.add(Dense(2))\t\t\t#because we have 2 class\r\n","model_medium.add(Activation('softmax'))\r\n","\r\n","model_medium.summary()\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *******************        COMPILATION       **************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","model_medium.compile(loss='categorical_crossentropy',\r\n","            optimizer=keras.optimizers.Adadelta(learning_rate=1, name='Adadelta'),\r\n","            metrics=['accuracy'])\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *******************        TRAINING       *****************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","with tf.device('/device:GPU:0'):\r\n","\r\n","  history = model_medium.fit(\r\n","    train_dataset,\r\n","    epochs=epochs,\r\n","    validation_data=validation_dataset)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# *****************        SAVE MODEL        ****************************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","model_medium.save(name_model_medium)\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ********************        PLOT RESULTS        ***********************\r\n","# ***********************************************************************\r\n","\r\n","\r\n","acc = history.history['accuracy']\r\n","val_acc = history.history['val_accuracy']\r\n","\r\n","loss = history.history['loss']\r\n","val_loss = history.history['val_loss']\r\n","\r\n","epochs_range = range(epochs)\r\n","\r\n","plt.figure(figsize=(8, 8))\r\n","plt.subplot(1, 2, 1)\r\n","plt.plot(epochs_range, acc, label='Training Accuracy')\r\n","plt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\n","plt.legend(loc='lower right')\r\n","plt.title('Training and Validation Accuracy_'+str(img_width)+' x '+str(img_height))\r\n","\r\n","plt.subplot(1, 2, 2)\r\n","plt.plot(epochs_range, loss, label='Training Loss')\r\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\r\n","plt.legend(loc='upper right')\r\n","plt.title('Training and Validation Loss_'+str(img_width)+' x '+str(img_height))\r\n","plt.show()\r\n","\r\n","\r\n","\r\n","# ***********************************************************************\r\n","# ***********************        TEST        ****************************\r\n","# ***********************************************************************\r\n","\r\n","with tf.device('/device:GPU:0'):\r\n","\r\n","  test_result = model_medium.evaluate(test_dataset)\r\n","\r\n","  \r\n","print(\"size of images: \", img_width,img_height)\r\n","print(\"test_result: \", test_result)\r\n","\r\n","\r\n","print ('Time taken for development model small {} sec\\n'.format(time.time() - start))"],"execution_count":null,"outputs":[]}]}